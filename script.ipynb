{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root and Exponentiation 开根号/求平方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "x=9\n",
    "up=1/2\n",
    "print(pow(x,up))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quartile 四分距"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quartile(Data):\n",
    "    maximum = np.max(Data)\n",
    "    minimum = np.min(Data)   \n",
    "    Data.sort() # odd\n",
    "    # median\n",
    "    index=(int)(len(Data)/2)\n",
    "    if (len(Data)%2) == 0:     \n",
    "        median = (Data[index]+Data[index-1])/2\n",
    "        leftdata = arr[:index]\n",
    "        rightdata = arr[index:]\n",
    "    else:       \n",
    "        median = Data[index]\n",
    "        leftdata = arr[:index+1] # including median\n",
    "        rightdata = arr[index:]\n",
    "    # Q1 \n",
    "    leftindex=(int)(len(leftdata)/2)\n",
    "    if(len(leftdata)%2) ==0:\n",
    "        q1 = (leftdata[leftindex]+leftdata[leftindex-1])/2\n",
    "    else:\n",
    "        q1 = leftdata[leftindex]\n",
    "    # Q3\n",
    "    rightindex=(int)(len(rightdata)/2)\n",
    "    if(len(leftdata)%2) ==0:\n",
    "        q3 = (rightdata[rightindex]+rightdata[rightindex-1])/2\n",
    "    else:\n",
    "        q3 = rightdata[rightindex]\n",
    "    # IQR\n",
    "    IQR = q3-q1\n",
    "    new_max= q3+1.5*IQR\n",
    "    new_min= q1-1.5*IQR\n",
    "    # Outlier\n",
    "    outl1 = Data[Data<new_min]\n",
    "    outl2 = Data[Data>new_max]\n",
    "    if outl1.size>0 and outl2.size>0:\n",
    "        outl = np.concatenate((outl1,outl2))\n",
    "    elif outl1.size>0: \n",
    "        outl= outl1\n",
    "    elif outl2.size>0: \n",
    "        outl= outl2\n",
    "    else:\n",
    "        outl= None\n",
    "    return minimum,maximum,median,q1,q3,IQR,outl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " min:0.000000\n",
      " max:50.000000\n",
      " median:19.000000\n",
      " Q1:15.000000\n",
      " Q3:20.500000\n",
      " IQR:5.500000\n",
      " mode:19.000000\n",
      "\n",
      "outlier: [ 0  5 30 50]\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([0,5,14,16,17,19,19,19,22,30,50])\n",
    "mi,mx,m,q1,q3,iqr,outlier=quartile(arr)\n",
    "md = mode(arr)[0][0]\n",
    "print(' min:%f\\n max:%f\\n median:%f\\n Q1:%f\\n Q3:%f\\n IQR:%f\\n mode:%f\\n' % (mi,mx,m,q1,q3,iqr,md))\n",
    "print('outlier:',outlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean, Var 均值，方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mean:1516.666667\n",
      " var:2334722.222222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr1=np.array([100,400,600,800,3000,4200])\n",
    "print(' mean:%f\\n var:%f\\n' % (np.mean(arr1),np.var(arr1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170.0\n"
     ]
    }
   ],
   "source": [
    "arr2 = np.array([8,10,15,35,50,52,85,89,92,158,201,251])\n",
    "bin_step=(np.max(arr2)-np.min(arr2))/3\n",
    "print(np.min(arr2)+2*bin_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance between tow points 两点or两vector（多维）间距"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Manhattan distance 曼哈顿距离 r=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Manhat_dist(point1,point2):\n",
    "    if len(point1)!=len(point2):\n",
    "        return \"bits not matching\"\n",
    "    temp=0\n",
    "    for i in range(len(point1)):\n",
    "        temp+=abs(point1[i]-point2[i])\n",
    "   \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "P1 =(1,0,1,0,1,1,0,0,0,1)\n",
    "P2 =(1,0,0,0,1,1,1,0,0,0)\n",
    "result=Manhat_dist(P1,P2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Euclidean distance 欧氏距离  r=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Euclid_dist(point1,point2):\n",
    "    if len(point1)!=len(point2):\n",
    "        return \"bits not matching\"\n",
    "    \n",
    "    temp=0\n",
    "    for i in range(len(point1)):\n",
    "        temp+=pow((point1[i]-point2[i]),2)\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before root: 13\n",
      "Number of distance is: 3.605551275463989\n"
     ]
    }
   ],
   "source": [
    "# input two data points in the same dimension\n",
    "P1 =(0,2)\n",
    "P2 =(3,4)\n",
    "result=Euclid_dist(P1,P2)\n",
    "print(\"Before root:\",result)  # before root\n",
    "print(\"Number of distance is:\",math.sqrt(result)) #  after root, real value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bits not matching\n"
     ]
    }
   ],
   "source": [
    "training_0 = np.array([[0,1],\n",
    "                      [0,0],\n",
    "                      [1,1],\n",
    "                       [0,1],\n",
    "                       [1,0],\n",
    "                       [0,0],\n",
    "                       [1,1],\n",
    "                       [0,0],\n",
    "                       [1,0],\n",
    "                       [1,0]\n",
    "                      ])\n",
    "training_0_label = np.array([1,2,1,1,1,2,1,2,1,2])\n",
    "test_0 =np.array([[2/3,1/3],[2/3,1/3],[2/3,1/3],[2/3,1/3],[2/3,1/3],[2/3,1/3],[2/3,1/3],[2/3,1/3],[2/3,1/3],[2/3,1/3]])\n",
    "result_0 = Euclid_dist(training_0,test_0)\n",
    "print(result_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Chebyshev distance 切比雪夫距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Chebyshev_dist(point1,point2):\n",
    "    if point1.size !=point2.size:\n",
    "        return \"bits not matching\"\n",
    "    return np.max(abs(point1-point2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chebyshev distance: 3\n"
     ]
    }
   ],
   "source": [
    "P1 =np.array([0,2])\n",
    "P2 =np.array([3,4])\n",
    "result=Chebyshev_dist(P1,P2)\n",
    "print(\"Chebyshev distance:\",result) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard & SM coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coef_calc(v1,v2):\n",
    "    \n",
    "    M01=0\n",
    "    M10=0\n",
    "    M00=0\n",
    "    M11=0\n",
    "    for i in range(P1.size):\n",
    "        if P1[i]==0 and P2[i]==0:\n",
    "            M00+=1\n",
    "        elif P1[i]!=0 and P2[i]==0:\n",
    "            M01+=1\n",
    "        elif P1[i]==0 and P2[i]!=0:\n",
    "            M10+=1 \n",
    "        else:\n",
    "            M11+=1\n",
    "    \n",
    "    SMC = (M11+M00)/(M01+M10+M11+M00)\n",
    "    JA = (M11)/(M01+M10+M11)\n",
    "    \n",
    "    return JA,SMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard value:0.500000\n",
      " SM value:0.700000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "P1 =np.array([1,0,1,0,1,1,0,0,0,1])\n",
    "P2 =np.array([1,0,0,0,1,1,1,0,0,0])\n",
    "jac,smc=coef_calc(P1,P2)\n",
    "print('Jaccard value:%f\\n SM value:%f\\n'%(jac,smc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear  equation calculation 线性方程计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_calculation(W,X,b):\n",
    "    return ((np.dot(X, W.T))+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear calcucating result is: [[-0.1846]]\n"
     ]
    }
   ],
   "source": [
    "# W,X should be in the same dimensions\n",
    "Wvector= np.array([(0.463,0.81,0.55)])   # input coefficients W \n",
    "Xvector= np.array([(-1.2,1.1,-0.4)])       # input variables X \n",
    "bias= -0.3                      # input bias\n",
    "lin_result = linear_calculation(Wvector,Xvector,bias)\n",
    "print(\"linear calcucating result is:\",lin_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid result is: 0.45398061001404805\n"
     ]
    }
   ],
   "source": [
    "sigmoid_x= lin_result\n",
    "sigmoid_result=sigmoid(sigmoid_x)\n",
    "print(\"sigmoid result is:\",sigmoid_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature map of CNN by kernel 特征提取/卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_featureMap(kernel,data):\n",
    "    \n",
    "    column_loop=data.shape[1]-kernel.shape[1]+1 # 横向取卷积区域次数\n",
    "    row_loop=data.shape[0]-kernel.shape[0]+1 # 换行次数\n",
    "    outputMatrix = np.zeros([row_loop,column_loop])\n",
    "    \n",
    "    for i in range(row_loop):\n",
    "        for j in range(column_loop):\n",
    "            conv_area = data[i:(i+kernel.shape[0]),j:(j+kernel.shape[1])] \n",
    "            conv_result = np.sum(conv_area*kernel) # the sum of the star product\n",
    "            outputMatrix[i,j]=conv_result           \n",
    "    \n",
    "    return outputMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.  1.  1.  4.  2.  3.]\n",
      " [ 0.  4.  2. -2.  4.  3.]\n",
      " [ 4. -1.  3.  2.  3.  1.]\n",
      " [-2.  4.  1.  3. -2.  2.]\n",
      " [-2.  1.  1.  4.  1.  1.]\n",
      " [ 3. -1.  1.  4.  2.  3.]]\n"
     ]
    }
   ],
   "source": [
    "CNN_Kerner=np.array([[-1,2,-1],\n",
    "                 [0,0,2],\n",
    "                 [2,-1,1]])\n",
    "inputMatrix=np.array([[0,1,0,1,1,0,1,0],\n",
    "                     [1,0,1,0,0,1,1,0],\n",
    "                     [0,1,0,1,1,0,0,1],\n",
    "                     [1,0,0,0,1,0,1,1],\n",
    "                     [1,0,0,1,1,0,0,0],\n",
    "                     [0,1,0,0,0,1,1,0],     \n",
    "                     [0,1,0,0,0,1,1,0],\n",
    "                     [0,0,1,1,0,1,0,0]])\n",
    "featureMap_result = CNN_featureMap(CNN_Kerner,inputMatrix)\n",
    "print(featureMap_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature map pooling      CNN池化 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_maxPooling(scale,featureMap):\n",
    "    \n",
    "    row_slice=scale[0]  # stride\n",
    "    column_slice=scale[1] # stride\n",
    "    row=featureMap.shape[0] # map size\n",
    "    column=featureMap.shape[1] # map size\n",
    "    # loop times calculation\n",
    "    loop_row1 = row/row_slice  \n",
    "    loop_row2 = (int)(row/row_slice)\n",
    "    loop_column1 = column/column_slice\n",
    "    loop_column2 = (int)(column/column_slice) \n",
    "    if loop_row1>loop_row2:\n",
    "        loop_row2+=1\n",
    "    loop_row = loop_row2\n",
    "    if loop_column1>loop_column2:\n",
    "        loop_column2+=1\n",
    "    loop_column = loop_column2\n",
    "    \n",
    "    #print(loop_row,loop_column) # result shape\n",
    "    pooled_map = np.zeros([loop_row,loop_column])  # store max data\n",
    "    for i in range(loop_row):\n",
    "        for j in range(loop_column):\n",
    "            if (i==loop_row-1): # --->most down side\n",
    "                if (j==loop_column-1):  # --->most right side     \n",
    "                    pooled_map[i,j]=np.max(featureMap[(i*row_slice):,(j*column_slice):]) # final one\n",
    "                else:\n",
    "                    pooled_map[i,j]=np.max(featureMap[(i*row_slice):,(j*column_slice):((j+1)*column_slice)]) # final row\n",
    "            else:                \n",
    "                if (j==loop_column-1):          \n",
    "                    pooled_map[i,j]=np.max(featureMap[(i*row_slice):((i+1)*row_slice),(j*column_slice):]) # final column but not final row\n",
    "                else:\n",
    "                    pooled_map[i,j]=np.max(featureMap[(i*row_slice):((i+1)*row_slice),(j*column_slice):((j+1)*column_slice)]) # not final row/column\n",
    "           \n",
    "                \n",
    "    return pooled_map\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 4., 4.],\n",
       "       [4., 3., 3.],\n",
       "       [3., 4., 3.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameter0: stride\n",
    "CNN_maxPooling((2,2),featureMap_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Weight，Perceptron      感知机权值更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Perceptron(W,X,y):\n",
    "    \n",
    "    classified_result = y * (np.sum(X*W))\n",
    "\n",
    "    if classified_result <= 0:\n",
    "        W = W + (y*X)\n",
    "        return W,'wrong',classified_result\n",
    "    else:\n",
    "        return W,'right',classified_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right classfied, W should keep to [0 1 0]\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# data input by steps\n",
    "W_ = np.array([0,1,0])\n",
    "\n",
    "X_ = np.array([1,-0.5,-0.5])\n",
    "y_ = -1\n",
    "\n",
    "W_,Message,C_result=Perceptron(W_,X_,y_)\n",
    "if Message=='wrong':\n",
    "    print(\"Wrongly classfied, W should be updated to\",W_ )\n",
    "    print(C_result)\n",
    "else:\n",
    "    print(\"Right classfied, W should keep to\",W_ )\n",
    "    print(C_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ min-max normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxminNor(x,MIN,MAX,MIN_new,MAX_new):\n",
    "    return ((x-MIN)/(MAX-MIN))*(MAX_new-MIN_new)+MIN_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After min-max normalization, the result is [  0.           7.31707317  12.19512195  17.07317073  70.73170732\n",
      " 100.        ]\n"
     ]
    }
   ],
   "source": [
    "Xvalue=arr1\n",
    "MinValue=100\n",
    "MaxValue=4200\n",
    "MinValue_N=0\n",
    "MaxValue_N=100\n",
    "nor_result=maxminNor(Xvalue,MinValue,MaxValue,MinValue_N,MaxValue_N)\n",
    "print(\"After min-max normalization, the result is\",nor_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Znor(Xset,Xpoint):\n",
    "    x_bar = np.mean(Xset)\n",
    "    std = np.std(Xset)\n",
    "    return (Xpoint-x_bar)/std\n",
    "\n",
    "def Znor_given(Xpoint,x_bar,std):\n",
    "    return (Xpoint-x_bar)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.92715014 -0.73081246 -0.59992068 -0.46902889  0.97078073  1.75613144]\n"
     ]
    }
   ],
   "source": [
    "Xset=np.array([-4,-2,0,2,4])\n",
    "Xpoint=4\n",
    "print(Znor(arr1,arr1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Decimal normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecimalNor(x):\n",
    "    negative=False\n",
    "    if x<0:\n",
    "        x=-x\n",
    "        negative=True\n",
    "    temp=x   # just for calculate the bit of number x\n",
    "    count=1\n",
    "    while (temp/10) > 1:\n",
    "        temp=temp/10\n",
    "        count=count+1\n",
    "    \n",
    "    if negative:\n",
    "         return -x/pow(10,count)\n",
    "    else:\n",
    "        return x/pow(10,count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    }
   ],
   "source": [
    "Xvalue=4\n",
    "print(DecimalNor(Xvalue))  # output should be in range [-1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy calculation for Dicision tree  决策树-信息熵相关计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ I(h)=-log(p(h)),based on log2   ,h belongs to H\n",
    "+ Entropy(S)=I(H)=Expectation(I(h1,h2,,,,hn)) = sum(-p(hi)I(hi))  \n",
    "+ Gain(S,A)= Entropy(S)- Remainder(A)  \n",
    "+ Remainder(A)= sum( Probability(k) * Entropy(k)) , k is the value of attribute A, sum all K in A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Entropy(Ratio):  # Label Ratio \n",
    "    return np.sum(-Ratio*np.log2(Ratio))\n",
    "\n",
    "\n",
    "def InformationGain(H ,value_Entropy,value_Prob):  \n",
    "    '''\n",
    "    H is the state entropy befor expanding this attribute;\n",
    "    value_Entropy is the entropy in each value itself\n",
    "    value_Prob is the propotion of each value in this attribute\n",
    "    '''\n",
    "    return H - np.sum(value_Prob * value_Entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State entropy      H(S)= 0.954434002924965\n",
      "InformationGain    Gain(S,A)= 0.015712127384097885\n",
      "SplitInformation   H(A)= 1.561278124459133\n",
      "Using in C.45      GainRatio(S,A)= 0.010063631288974199\n"
     ]
    }
   ],
   "source": [
    "#### State Entropy\n",
    "Ratios=np.array([3/8,5/8])# State entropy, label ratio. 1)填当前state的samples中各个labels的比例\n",
    "H_S = Entropy(Ratios)\n",
    "print(\"State entropy      H(S)=\" ,H_S)\n",
    "\n",
    "# Attribute Information Gain\n",
    "Ratios_Value1=np.array([2/3,1/3])   # 2)在当前state的samples里，填节点中各个value对于各个labels的比例\n",
    "Ratios_Value2=np.array([2/3,1/3])\n",
    "Ratios_Value3=np.array([1/2,1/2]) # adjust by the num of kind of value in this attribute \n",
    "\n",
    "Value_Entropy = np.array([Entropy(Ratios_Value1),Entropy(Ratios_Value2),Entropy(Ratios_Value3)])  # 3) 修改value size\n",
    "Value_Prob = np.array([3/8,3/8,2/8])  # 4) 在当前state的samples里，填各个value的比例,(value1,value2,value3)\n",
    "\n",
    "Gain=InformationGain(H_S,Value_Entropy,Value_Prob)\n",
    "print(\"InformationGain    Gain(S,A)=\",Gain)\n",
    "\n",
    "if True:  # Switch using Gain or GainRatio\n",
    "    # Attribute GainRatio \n",
    "    H_A = Entropy(Value_Prob) \n",
    "    print(\"SplitInformation   H(A)=\",H_A)\n",
    "    print(\"Using in C.45      GainRatio(S,A)=\",(Gain/H_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Gini index\n",
    "+ G(t)=1-sum((p(j|t))^2)  | node t, class j\n",
    "+ G_split(a)= w1 * G(t1) + w2 * G(t2) | w1+w2=1 , the value lower , as split attribute better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gini(data):\n",
    "    data = data/np.sum(data)\n",
    "    return 1-np.sum(pow(data,2))\n",
    "                    \n",
    "def Gini_Split(g_Value,w_Label):\n",
    "    return np.sum(g_Value * w_Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini value is: 0.5\n"
     ]
    }
   ],
   "source": [
    "arr_gini =np.array([25,25]) # number of labels\n",
    "print('Gini value is:',Gini(arr_gini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GiniSplit value is: 0.5\n"
     ]
    }
   ],
   "source": [
    "arr_gvalue = np.array([0,0.5])\n",
    "arr_wLabel = np.array([0,50]) # number of labels\n",
    "arr_wLabel = arr_wLabel/np.sum(arr_wLabel)\n",
    "print('GiniSplit value is:',Gini_Split(arr_gvalue,arr_wLabel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11099999999999999"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.444-0.333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4388912221755565"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.209/(0.4*0.7*0.8*0.8+0.6*0.5*0.8*0.8+0.4*0.3*0.5*0.5+0.6*0.5*0.5*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "def Sum_positive(listX):\n",
    "    SUM=0\n",
    "    for i in listX:\n",
    "        if i>0:\n",
    "            SUM+=i\n",
    "    return SUM\n",
    "print(Sum_positive([1,2,3,7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, (3, 2, 5), 3, 2, 5]\n"
     ]
    }
   ],
   "source": [
    "a=[1,4]\n",
    "b=(3,2,5)\n",
    "a.append(b)\n",
    "a.extend(b)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.29903811  1.73205081]\n",
      " [-0.4330127   0.4330127 ]\n",
      " [ 0.4330127  -0.8660254 ]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[2, 9],\n",
    "            [4, 6],\n",
    "             [6, 3]])\n",
    "((A-np.mean(A))/np.std(A)).T @ ((A-np.mean(A))/np.std(A))\n",
    "print((A-np.mean(A))/np.std(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
